<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>Smart AI Cinematic Generator</title>
<style>
body{margin:0;padding:20px;background:#0b1220;color:#e6eef6;font-family:Inter,system-ui,sans-serif;display:flex;justify-content:center;align-items:flex-start;min-height:100vh}
.container{max-width:1000px;width:100%;background:rgba(255,255,255,0.05);border-radius:12px;padding:20px;box-shadow:0 0 25px rgba(0,0,0,0.4)}
h1{margin-top:0;color:#6ee7b7;text-align:center}
label{display:block;margin-top:12px;font-size:14px}
textarea,input,select{width:100%;padding:10px;border-radius:8px;border:none;background:rgba(255,255,255,0.1);color:#fff;font-size:15px}
button{margin-top:12px;background:#6ee7b7;color:#0b1220;border:none;padding:10px 16px;border-radius:8px;cursor:pointer;font-weight:600}
video{width:100%;margin-top:14px;border-radius:8px;background:#000}
.note{font-size:13px;color:#aaa;text-align:center;margin-top:10px}
#uploads{margin-top:8px}
#uploads input{margin-top:4px}
</style>
</head>
<body>
<div class="container">
<h1>ðŸ¤– Smart AI Cinematic Generator</h1>

<label>Prompt (Describe scene & actions)</label>
<textarea id="prompt" rows="5" placeholder="e.g. Cat sees fish bowl, jumps, meows"></textarea>

<label>Scene Duration (seconds)</label>
<input id="sceneDuration" type="number" min="1" max="20" value="5">

<label>OpenAI API Key (TTS)</label>
<input id="openaiKey" type="text" placeholder="Paste your OpenAI API key">

<label>Kaiber API Key (AI Video)</label>
<input id="kaiberKey" type="text" placeholder="Paste your Kaiber API key">

<label>Upload Object Image (optional)</label>
<div id="uploads">
  <input type="file" id="userImage" accept="image/*">
</div>

<button id="generate">Generate Smart Cinematic Reel</button>
<video id="preview" controls></video>
<div class="note">Automatically animates objects, handles multi-step behaviors, motion, camera, TTS, and sound effects.</div>
</div>

<script>
const btn=document.getElementById('generate');
const preview=document.getElementById('preview');
const userImageInput=document.getElementById('userImage');

function easeInOut(t){return t<0.5?2*t*t:1-(--t)*(2*t-1);}

async function fileToBase64(file){
  return new Promise(res=>{
    const reader=new FileReader();
    reader.onload=()=>res(reader.result);
    reader.readAsDataURL(file);
  });
}

// Generate AI video for a scene (multi-step behavior)
async function generateSceneVideo(prompt,duration,userImage,kaiberKey){
  const payload={
    prompt,
    duration,
    style:'cinematic',
    behavior:'smart',
    userImage:userImage?await fileToBase64(userImage):null
  };
  const resp=await fetch('https://api.kaiber.ai/v1/generate',{
    method:'POST',
    headers:{'Content-Type':'application/json','Authorization':'Bearer '+kaiberKey},
    body:JSON.stringify(payload)
  });
  if(!resp.ok) throw new Error('Kaiber API error: '+resp.status);
  const data=await resp.json();
  const videoResp=await fetch(data.videoUrl);
  return await videoResp.blob();
}

// Generate TTS for a scene
async function generateTTS(openaiKey,text){
  const resp=await fetch('https://api.openai.com/v1/audio/speech',{
    method:'POST',
    headers:{'Authorization':'Bearer '+openaiKey,'Content-Type':'application/json'},
    body:JSON.stringify({model:'gpt-4o-mini-tts',voice:'alloy',input:text})
  });
  if(!resp.ok) throw new Error('TTS API error: '+resp.status);
  return await resp.blob();
}

// Merge clips with smooth frame-by-frame motion
async function mergeClipsWithAudio(clips,audios){
  const canvas=document.createElement('canvas');
  const ctx=canvas.getContext('2d');
  canvas.width=720; canvas.height=1280;
  const fps=30;
  const stream=canvas.captureStream(fps);
  const rec=new MediaRecorder(stream,{mimeType:'video/webm'});
  const chunks=[];
  rec.ondataavailable=e=>{if(e.data.size) chunks.push(e.data)};
  rec.start();

  for(let i=0;i<clips.length;i++){
    const clipBlob=clips[i];
    const audioBlob=audios[i];
    const videoEl=document.createElement('video');
    videoEl.src=URL.createObjectURL(clipBlob);
    videoEl.muted=true; await videoEl.play().catch(()=>{});
    const audioEl=document.createElement('audio');
    audioEl.src=URL.createObjectURL(audioBlob);
    audioEl.play().catch(()=>{});

    const duration=videoEl.duration||4;
    const totalFrames=Math.ceil(fps*duration);
    for(let f=0;f<totalFrames;f++){
      ctx.clearRect(0,0,canvas.width,canvas.height);
      const t=easeInOut(f/totalFrames);

      // Smooth transforms
      const scale=1+t*0.1;
      const dx=t*50; const dy=t*30;
      ctx.save();
      ctx.translate(dx,dy);
      ctx.scale(scale,scale);
      ctx.drawImage(videoEl,0,0,canvas.width,canvas.height);
      ctx.restore();

      await new Promise(r=>setTimeout(r,1000/fps));
    }
    videoEl.pause();
    audioEl.pause();
  }

  rec.stop();
  return new Promise(res=>rec.onstop=()=>res(new Blob(chunks,{type:'video/webm'})));
}

btn.onclick=async()=>{
  const prompt=document.getElementById('prompt').value.trim();
  const duration=parseFloat(document.getElementById('sceneDuration').value)||5;
  const openaiKey=document.getElementById('openaiKey').value.trim();
  const kaiberKey=document.getElementById('kaiberKey').value.trim();
  const userImage=userImageInput.files[0]||null;

  if(!prompt||!openaiKey||!kaiberKey) return alert('Fill all required fields');

  btn.disabled=true; btn.textContent='Generating Smart Cinematic Reel...';

  try{
    const clip=await generateSceneVideo(prompt,duration,userImage,kaiberKey);
    const audio=await generateTTS(openaiKey,prompt);
    const final=await mergeClipsWithAudio([clip],[audio]);
    preview.src=URL.createObjectURL(final);
  }catch(e){console.error(e); alert('Error: '+e);}
  
  btn.disabled=false; btn.textContent='Generate Smart Cinematic Reel';
};
</script>
</body>
</html>
